{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89473922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers>=4.45.2 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (4.56.2)\n",
      "Requirement already satisfied: datasets in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (4.3.0)\n",
      "Requirement already satisfied: accelerate in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (1.12.0)\n",
      "Requirement already satisfied: bitsandbytes in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (0.48.2)\n",
      "Requirement already satisfied: peft in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (0.18.0)\n",
      "Requirement already satisfied: trl in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (0.22.2)\n",
      "Requirement already satisfied: filelock in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from transformers>=4.45.2) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from transformers>=4.45.2) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from transformers>=4.45.2) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from transformers>=4.45.2) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from transformers>=4.45.2) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from transformers>=4.45.2) (2025.11.3)\n",
      "Requirement already satisfied: requests in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from transformers>=4.45.2) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from transformers>=4.45.2) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from transformers>=4.45.2) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from transformers>=4.45.2) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.45.2) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.45.2) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.45.2) (1.2.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: psutil in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from accelerate) (7.1.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from accelerate) (2.9.0)\n",
      "Requirement already satisfied: setuptools in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.6)\n",
      "Requirement already satisfied: jinja2 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from requests->transformers>=4.45.2) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from requests->transformers>=4.45.2) (2.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/gradde/Projects/vlab/.venv/lib64/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"transformers>=4.45.2\" datasets accelerate bitsandbytes peft trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4675b794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('alespalla/chatbot_instruction_prompts')\n",
    "\n",
    "# split_dataset = dataset['train'].train_test_split(test_size=0.2)\n",
    "dataset_loadtime = timeit.default_timer() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "854f131a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 2 files: 100%|██████████| 2/2 [04:27<00:00, 133.85s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:57<00:00, 28.88s/it]\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, BitsAndBytesConfig\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "\n",
    "model_checkpoint = \"ibm-granite/granite-3.0-2b-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "BitsAndBytesConfig\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16 # if not set will throw a warning about slow speeds when training\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "  model_checkpoint,\n",
    "  quantization_config=bnb_config,\n",
    "  device_map=\"auto\"\n",
    "\n",
    ")\n",
    "\n",
    "model_loadtime = timeit.default_timer() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19d0d981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter:   0%|          | 0/6000 [00:00<?, ? examples/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response_tokens) <= \u001b[32m200\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(prompt_tokens) <= \u001b[32m50\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Apply the filter to both train and test splits\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m train_filtered = \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m6000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilter_long_examples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m test_filtered = dataset[\u001b[33m'\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m'\u001b[39m].select(\u001b[38;5;28mrange\u001b[39m(\u001b[32m500\u001b[39m)).filter(filter_long_examples)\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtrain_filtered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_filtered)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m observations\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mtest_filtered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test_filtered)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m observations\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/vlab/.venv/lib64/python3.12/site-packages/datasets/arrow_dataset.py:562\u001b[39m, in \u001b[36mtransmit_format.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    555\u001b[39m self_format = {\n\u001b[32m    556\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_type,\n\u001b[32m    557\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mformat_kwargs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_kwargs,\n\u001b[32m    558\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_columns,\n\u001b[32m    559\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33moutput_all_columns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._output_all_columns,\n\u001b[32m    560\u001b[39m }\n\u001b[32m    561\u001b[39m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m562\u001b[39m out: Union[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDatasetDict\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    563\u001b[39m datasets: \u001b[38;5;28mlist\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mlist\u001b[39m(out.values()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/vlab/.venv/lib64/python3.12/site-packages/datasets/fingerprint.py:442\u001b[39m, in \u001b[36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    438\u001b[39m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[32m    440\u001b[39m \u001b[38;5;66;03m# Call actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[38;5;66;03m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:  \u001b[38;5;66;03m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/vlab/.venv/lib64/python3.12/site-packages/datasets/arrow_dataset.py:3914\u001b[39m, in \u001b[36mDataset.filter\u001b[39m\u001b[34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[39m\n\u001b[32m   3911\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inspect.iscoroutinefunction(function) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m batched:\n\u001b[32m   3912\u001b[39m     batch_size = \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m3914\u001b[39m indices = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3916\u001b[39m \u001b[43m        \u001b[49m\u001b[43masync_get_indices_from_mask_function\u001b[49m\n\u001b[32m   3917\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minspect\u001b[49m\u001b[43m.\u001b[49m\u001b[43miscoroutinefunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3918\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mget_indices_from_mask_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3920\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3921\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3922\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3923\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3924\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3926\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   3927\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   3928\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mindices\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mValue\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muint64\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3929\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatched\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   3930\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3931\u001b[39m \u001b[43m    \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumn_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3932\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3933\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3934\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3935\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3936\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3937\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3938\u001b[39m \u001b[43m    \u001b[49m\u001b[43msuffix_template\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuffix_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3939\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnew_fingerprint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3940\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3941\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFilter\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3942\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3943\u001b[39m new_dataset = copy.deepcopy(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m   3944\u001b[39m new_dataset._indices = indices.data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/vlab/.venv/lib64/python3.12/site-packages/datasets/arrow_dataset.py:562\u001b[39m, in \u001b[36mtransmit_format.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    555\u001b[39m self_format = {\n\u001b[32m    556\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_type,\n\u001b[32m    557\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mformat_kwargs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_kwargs,\n\u001b[32m    558\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_columns,\n\u001b[32m    559\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33moutput_all_columns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._output_all_columns,\n\u001b[32m    560\u001b[39m }\n\u001b[32m    561\u001b[39m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m562\u001b[39m out: Union[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDatasetDict\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    563\u001b[39m datasets: \u001b[38;5;28mlist\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mlist\u001b[39m(out.values()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/vlab/.venv/lib64/python3.12/site-packages/datasets/arrow_dataset.py:3332\u001b[39m, in \u001b[36mDataset.map\u001b[39m\u001b[34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc, try_original_type)\u001b[39m\n\u001b[32m   3330\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3331\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m unprocessed_kwargs \u001b[38;5;129;01min\u001b[39;00m unprocessed_kwargs_per_job:\n\u001b[32m-> \u001b[39m\u001b[32m3332\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43munprocessed_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3333\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcheck_if_shard_done\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3335\u001b[39m \u001b[38;5;66;03m# Avoids PermissionError on Windows (the error: https://github.com/huggingface/datasets/actions/runs/4026734820/jobs/6921621805)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/vlab/.venv/lib64/python3.12/site-packages/datasets/arrow_dataset.py:3688\u001b[39m, in \u001b[36mDataset._map_single\u001b[39m\u001b[34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, try_original_type)\u001b[39m\n\u001b[32m   3686\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3687\u001b[39m     _time = time.time()\n\u001b[32m-> \u001b[39m\u001b[32m3688\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miter_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_iterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3689\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_examples_in_batch\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3690\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mupdate_data\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/vlab/.venv/lib64/python3.12/site-packages/datasets/arrow_dataset.py:3638\u001b[39m, in \u001b[36mDataset._map_single.<locals>.iter_outputs\u001b[39m\u001b[34m(shard_iterable)\u001b[39m\n\u001b[32m   3636\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3637\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[32m-> \u001b[39m\u001b[32m3638\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m i, \u001b[43mapply_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/vlab/.venv/lib64/python3.12/site-packages/datasets/arrow_dataset.py:3561\u001b[39m, in \u001b[36mDataset._map_single.<locals>.apply_function\u001b[39m\u001b[34m(pa_inputs, indices, offset)\u001b[39m\n\u001b[32m   3559\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Utility to apply the function on a selection of columns.\"\"\"\u001b[39;00m\n\u001b[32m   3560\u001b[39m inputs, fn_args, additional_args, fn_kwargs = prepare_inputs(pa_inputs, indices, offset=offset)\n\u001b[32m-> \u001b[39m\u001b[32m3561\u001b[39m processed_inputs = \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3562\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m prepare_outputs(pa_inputs, inputs, processed_inputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/vlab/.venv/lib64/python3.12/site-packages/datasets/arrow_dataset.py:6746\u001b[39m, in \u001b[36mget_indices_from_mask_function\u001b[39m\u001b[34m(function, batched, with_indices, with_rank, input_columns, indices_mapping, *args, **fn_kwargs)\u001b[39m\n\u001b[32m   6744\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[32m   6745\u001b[39m             additional_args += (rank,)\n\u001b[32m-> \u001b[39m\u001b[32m6746\u001b[39m         mask.append(\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   6747\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6748\u001b[39m     \u001b[38;5;66;03m# inputs is a list of columns\u001b[39;00m\n\u001b[32m   6749\u001b[39m     columns: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m] = inputs\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mfilter_long_examples\u001b[39m\u001b[34m(example)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfilter_long_examples\u001b[39m(example):\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     prompt_tokens = \u001b[43mtokenizer\u001b[49m.tokenize(example[\u001b[33m'\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     32\u001b[39m     response_tokens = tokenizer.tokenize(example[\u001b[33m'\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m'\u001b[39m])  \u001b[38;5;66;03m# Tokenize the response\u001b[39;00m\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response_tokens) <= \u001b[32m200\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(prompt_tokens) <= \u001b[32m50\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import datasets\n",
    "\n",
    "def pirateify(batch):\n",
    "  prompts = [f\"make it sound like a pirate said this, do not include any preamble or explanation only piratify the following: {response}\" for response in batch['response']]\n",
    "  # Tokenize the inputs in batch and move them to GPU\n",
    "  inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True).to('cuda')\n",
    "  # Generate the pirate-like responses in batch\n",
    "  outputs = model.generate(**inputs, max_new_tokens=256, do_sample=True, top_p=0.95, temperature=0.7)\n",
    "  # Decode the generated tokens into text for each output in the batch\n",
    "  pirate_responses = []\n",
    "  for output in outputs:\n",
    "    pr = tokenizer.decode(output, skip_special_tokens=True)\n",
    "    if '\\n\\n' in pr:\n",
    "      pirate_responses.append(pr.split('\\n\\n')[-1])\n",
    "    else:\n",
    "      pirate_responses.append(pr)\n",
    "\n",
    "  # Move the outputs back to CPU (to free up GPU memory)\n",
    "  inputs = inputs.to('cpu')\n",
    "  outputs = outputs.to('cpu')\n",
    "  # Clear the GPU cache to release any unused memory\n",
    "  torch.cuda.empty_cache()\n",
    "  return {\n",
    "      'prompt': batch['prompt'],  # The original prompts (already a batch)\n",
    "      'response': pirate_responses  # The pirate responses, generated in batch\n",
    "  }\n",
    "\n",
    "\n",
    "def filter_long_examples(example):\n",
    "    prompt_tokens = tokenizer.tokenize(example['prompt'])\n",
    "    response_tokens = tokenizer.tokenize(example['response'])  # Tokenize the response\n",
    "    return len(response_tokens) <= 200 and len(prompt_tokens) <= 50\n",
    "\n",
    "# Apply the filter to both train and test splits\n",
    "train_filtered = dataset['train'].select(range(6000)).filter(filter_long_examples)\n",
    "test_filtered = dataset['test'].select(range(500)).filter(filter_long_examples)\n",
    "\n",
    "print(f\"train_filtered: {len(train_filtered)} observations\\ntest_filtered: {len(test_filtered)} observations\")\n",
    "pirate_train = train_filtered.select(range(1500)).map(pirateify, batched=True, batch_size=64)\n",
    "pirate_test = test_filtered.select(range(250)).map(pirateify, batched=True, batch_size=64)\n",
    "\n",
    "# Save the new dataset\n",
    "pirate_dataset = datasets.DatasetDict({\n",
    "    'train': pirate_train,\n",
    "    'test': pirate_test\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "906dec05",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pirate_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mpirate_dataset\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m].to_pandas().head()\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      3\u001b[39m torch.cuda.empty_cache()\n",
      "\u001b[31mNameError\u001b[39m: name 'pirate_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "pirate_dataset['train'].to_pandas().head()\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b9291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "input_text = \"<|user>What does 'inheritance' mean?\\n<|assistant|>\\n\"\n",
    "\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=100)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "\n",
    "model_check_loadtime = timeit.default_timer() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5556bcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "def formatting_prompts_func(example):\n",
    "    output_texts = []\n",
    "    for i in range(len(example['prompt'])):\n",
    "        text = f\"<|system|>\\nYou are a helpful assistant\\n<|user|>\\n{example['prompt'][i]}\\n<|assistant|>\\n{example['response'][i]}<|endoftext|>\"\n",
    "        output_texts.append(text)\n",
    "    return output_texts\n",
    "\n",
    "response_template = \"\\n<|assistant|>\\n\"\n",
    "\n",
    "from trl import DataCollatorForCompletionOnlyLM\n",
    "\n",
    "response_template_ids = tokenizer.encode(response_template, add_special_tokens=False)[2:]\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template_ids, tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "# Apply qLoRA\n",
    "qlora_config = LoraConfig(\n",
    "    r=16,  # The rank of the Low-Rank Adaptation\n",
    "    lora_alpha=32,  # Scaling factor for the adapted layers\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # Layer names to apply LoRA to\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\"\n",
    ")\n",
    "\n",
    "# Initialize the SFTTrainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=6,\n",
    "    per_device_eval_batch_size=6,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=100,\n",
    "    fp16=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "max_seq_length = 250\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=pirate_dataset['train'],\n",
    "    eval_dataset=pirate_dataset['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    peft_config = qlora_config,\n",
    "    formatting_func=formatting_prompts_func,\n",
    "    data_collator=collator,\n",
    "    max_seq_length=max_seq_length,\n",
    ")\n",
    "\n",
    "training_setup_loadtime = timeit.default_timer() - start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4bd39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "# Start training\n",
    "trainer.train()\n",
    "training_time = timeit.default_timer() - start_time\n",
    "model.save_pretrained(\"./results\")\n",
    "tokenizer.save_pretrained(\"./results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
